{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('comments_corpus.csv', names=[\"comment\", \"comment_id\", \"reply_count\", \"likes_count\"])\n",
    "data = df.drop(['comment_id', 'reply_count', 'likes_count'], axis=1)\n",
    "\n",
    "#first_col = data.pop('comment_id')\n",
    "#data.insert(0, 'comment_id', first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8023</th>\n",
       "      <td>1 for Mufasa On Godd He Was A Real One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>I don't know how I've become addicted to watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>1 just cuz you said there was about to be a bunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8537</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>It is INSANE that she doesn't realize that EVE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>You guys are the only ones that give me hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7296</th>\n",
       "      <td>My two favorite channels , I love al of you gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>maybe if she takes of those creepy eye lashes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8627</th>\n",
       "      <td>Woman are the picky ones, I wish they would sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment\n",
       "8023             1 for Mufasa On Godd He Was A Real One\n",
       "5665  I don't know how I've become addicted to watch...\n",
       "3490  1 just cuz you said there was about to be a bunch\n",
       "8537                                                  1\n",
       "2679  It is INSANE that she doesn't realize that EVE...\n",
       "2623       You guys are the only ones that give me hope\n",
       "7296  My two favorite channels , I love al of you gu...\n",
       "2370   maybe if she takes of those creepy eye lashes...\n",
       "8627  Woman are the picky ones, I wish they would sa...\n",
       "686                                                   1"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    result = emoji_pattern.sub(r'', punctuationfree)\n",
    "    return result\n",
    "\n",
    "\n",
    "#storing the puntuation free text\n",
    "data['clean_comment']= data['comment'].apply(lambda x: clean_text(x))\n",
    "\n",
    "#calculate average length of comments to filter out un useful commnets.\n",
    "data['Avg_length'] = data[\"clean_comment\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "#delete rows with comments less that 10 words long\n",
    "data = data.loc[data['Avg_length'] >=10]\n",
    "\n",
    "data = data.drop('Avg_length', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>clean_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>I’ve never approached a man first because I wo...</td>\n",
       "      <td>I’ve never approached a man first because I wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>Looks like a potato head but acts like a veget...</td>\n",
       "      <td>Looks like a potato head but acts like a veget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8018</th>\n",
       "      <td>She talks about her \"friend\" relationship and ...</td>\n",
       "      <td>She talks about her friend relationship and sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>HA HA HA HA HA HA HA, \"Hi\", \"Hey\" = ghosting t...</td>\n",
       "      <td>HA HA HA HA HA HA HA Hi Hey  ghosting time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6629</th>\n",
       "      <td>I've been married for 11 years and we just sta...</td>\n",
       "      <td>Ive been married for 11 years and we just star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>That word 'empowering' is such a bs word and w...</td>\n",
       "      <td>That word empowering is such a bs word and wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>That is the biggest straw man I have EVER seen...</td>\n",
       "      <td>That is the biggest straw man I have EVER seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9476</th>\n",
       "      <td>When I go to Mcdonald's I get a quarterpounder...</td>\n",
       "      <td>When I go to Mcdonalds I get a quarterpounder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>I would have a hard time being on bumble. I'm ...</td>\n",
       "      <td>I would have a hard time being on bumble Im pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8706</th>\n",
       "      <td>I'm married and it's cause I courted my husban...</td>\n",
       "      <td>Im married and its cause I courted my husband ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  \\\n",
       "5542  I’ve never approached a man first because I wo...   \n",
       "5012  Looks like a potato head but acts like a veget...   \n",
       "8018  She talks about her \"friend\" relationship and ...   \n",
       "332   HA HA HA HA HA HA HA, \"Hi\", \"Hey\" = ghosting t...   \n",
       "6629  I've been married for 11 years and we just sta...   \n",
       "9574  That word 'empowering' is such a bs word and w...   \n",
       "5078  That is the biggest straw man I have EVER seen...   \n",
       "9476  When I go to Mcdonald's I get a quarterpounder...   \n",
       "1072  I would have a hard time being on bumble. I'm ...   \n",
       "8706  I'm married and it's cause I courted my husban...   \n",
       "\n",
       "                                          clean_comment  \n",
       "5542  I’ve never approached a man first because I wo...  \n",
       "5012  Looks like a potato head but acts like a veget...  \n",
       "8018  She talks about her friend relationship and sh...  \n",
       "332          HA HA HA HA HA HA HA Hi Hey  ghosting time  \n",
       "6629  Ive been married for 11 years and we just star...  \n",
       "9574  That word empowering is such a bs word and wom...  \n",
       "5078     That is the biggest straw man I have EVER seen  \n",
       "9476  When I go to Mcdonalds I get a quarterpounder ...  \n",
       "1072  I would have a hard time being on bumble Im pr...  \n",
       "8706  Im married and its cause I courted my husband ...  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "data['polarity'] = data['clean_comment'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14774/3101464653.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['pol_cat'][data.polarity > 0] = 1\n",
      "/tmp/ipykernel_14774/3101464653.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['pol_cat'][data.polarity <= 0] = -1\n"
     ]
    }
   ],
   "source": [
    "data['pol_cat'] = \"\"\n",
    "data['pol_cat'][data.polarity > 0] = 1\n",
    "data['pol_cat'][data.polarity <= 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pol_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6627</th>\n",
       "      <td>The problem with Bumble is that it opens women...</td>\n",
       "      <td>The problem with Bumble is that it opens women...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>Lord, a perfect example of entitlement and ign...</td>\n",
       "      <td>Lord a perfect example of entitlement and igno...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>She's just saying all her own flaws and saying...</td>\n",
       "      <td>Shes just saying all her own flaws and saying ...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8136</th>\n",
       "      <td>Thanks for posting guys, i rarely comment and ...</td>\n",
       "      <td>Thanks for posting guys i rarely comment and s...</td>\n",
       "      <td>0.379545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6794</th>\n",
       "      <td>What she doesn’t realize is sure men will alwa...</td>\n",
       "      <td>What she doesn’t realize is sure men will alwa...</td>\n",
       "      <td>-0.064062</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>at 3:30 I have developed those skills, I still...</td>\n",
       "      <td>at 330 I have developed those skills I still l...</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>The whole reason why Bumble makes Women be the...</td>\n",
       "      <td>The whole reason why Bumble makes Women be the...</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>She's just mad about hitting the wall and stil...</td>\n",
       "      <td>Shes just mad about hitting the wall and still...</td>\n",
       "      <td>-0.348214</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>I’m sorry but we she mentioned dick sucking I ...</td>\n",
       "      <td>I’m sorry but we she mentioned dick sucking I ...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>Yo whats with the Christmas tree in October???...</td>\n",
       "      <td>Yo whats with the Christmas tree in October  T...</td>\n",
       "      <td>-0.216667</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>Hahaha..... A lioness will lay down toot that ...</td>\n",
       "      <td>Hahaha A lioness will lay down toot that thing...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>Wait… she talking about being worth more, but ...</td>\n",
       "      <td>Wait… she talking about being worth more but i...</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>Her analogy is wrong as when I pictured a hunt...</td>\n",
       "      <td>Her analogy is wrong as when I pictured a hunt...</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>And this is exactly whey that thick neck, big ...</td>\n",
       "      <td>And this is exactly whey that thick neck big h...</td>\n",
       "      <td>-0.075794</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>Hinge is probably next….. \\n\\nI’m getting tire...</td>\n",
       "      <td>Hinge is probably next… \\n\\nI’m getting tired ...</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7200</th>\n",
       "      <td>Man the laziness and emtitlement. Where has th...</td>\n",
       "      <td>Man the laziness and emtitlement Where has thi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7501</th>\n",
       "      <td>Why make a vid about now? Bumble been around f...</td>\n",
       "      <td>Why make a vid about now Bumble been around fo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>This is the same woman who dates teens and fbo...</td>\n",
       "      <td>This is the same woman who dates teens and fbo...</td>\n",
       "      <td>-0.245833</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>what blow my mind is the fact that she takes h...</td>\n",
       "      <td>what blow my mind is the fact that she takes h...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>Her *entire* channel is obsessing over and ana...</td>\n",
       "      <td>Her entire channel is obsessing over and analy...</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  \\\n",
       "6627  The problem with Bumble is that it opens women...   \n",
       "3134  Lord, a perfect example of entitlement and ign...   \n",
       "3584  She's just saying all her own flaws and saying...   \n",
       "8136  Thanks for posting guys, i rarely comment and ...   \n",
       "6794  What she doesn’t realize is sure men will alwa...   \n",
       "3377  at 3:30 I have developed those skills, I still...   \n",
       "4077  The whole reason why Bumble makes Women be the...   \n",
       "5547  She's just mad about hitting the wall and stil...   \n",
       "133   I’m sorry but we she mentioned dick sucking I ...   \n",
       "3615  Yo whats with the Christmas tree in October???...   \n",
       "3353  Hahaha..... A lioness will lay down toot that ...   \n",
       "3223  Wait… she talking about being worth more, but ...   \n",
       "4219  Her analogy is wrong as when I pictured a hunt...   \n",
       "6191  And this is exactly whey that thick neck, big ...   \n",
       "6482  Hinge is probably next….. \\n\\nI’m getting tire...   \n",
       "7200  Man the laziness and emtitlement. Where has th...   \n",
       "7501  Why make a vid about now? Bumble been around f...   \n",
       "3428  This is the same woman who dates teens and fbo...   \n",
       "7755  what blow my mind is the fact that she takes h...   \n",
       "2798  Her *entire* channel is obsessing over and ana...   \n",
       "\n",
       "                                          clean_comment  polarity pol_cat  \n",
       "6627  The problem with Bumble is that it opens women...  0.000000      -1  \n",
       "3134  Lord a perfect example of entitlement and igno...  1.000000       1  \n",
       "3584  Shes just saying all her own flaws and saying ...  0.700000       1  \n",
       "8136  Thanks for posting guys i rarely comment and s...  0.379545       1  \n",
       "6794  What she doesn’t realize is sure men will alwa... -0.064062      -1  \n",
       "3377  at 330 I have developed those skills I still l...  0.060000       1  \n",
       "4077  The whole reason why Bumble makes Women be the...  0.057143       1  \n",
       "5547  Shes just mad about hitting the wall and still... -0.348214      -1  \n",
       "133   I’m sorry but we she mentioned dick sucking I ... -0.500000      -1  \n",
       "3615  Yo whats with the Christmas tree in October  T... -0.216667      -1  \n",
       "3353  Hahaha A lioness will lay down toot that thing...  0.022222       1  \n",
       "3223  Wait… she talking about being worth more but i...  0.366667       1  \n",
       "4219  Her analogy is wrong as when I pictured a hunt... -0.166667      -1  \n",
       "6191  And this is exactly whey that thick neck big h... -0.075794      -1  \n",
       "6482  Hinge is probably next… \\n\\nI’m getting tired ... -0.300000      -1  \n",
       "7200  Man the laziness and emtitlement Where has thi...  0.000000      -1  \n",
       "7501  Why make a vid about now Bumble been around fo...  0.000000      -1  \n",
       "3428  This is the same woman who dates teens and fbo... -0.245833      -1  \n",
       "7755  what blow my mind is the fact that she takes h...  0.600000       1  \n",
       "2798  Her entire channel is obsessing over and analy... -0.033333      -1  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comments_lower']= data['clean_comment'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "def tokenize(text):\n",
    "    tokeniezd_word = word_tokenize(text)\n",
    "    return tokeniezd_word\n",
    "\n",
    "def sent_tokenize(text):\n",
    "    tokenized_sent = sent_tokenize(text)\n",
    "    return tokenized_sent\n",
    "\n",
    "data['tokenized'] = data['comments_lower'].apply(lambda x: tokenize(x))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#print(sys.getrecursionlimit())\n",
    "#sys.setrecursionlimit(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing nlp library\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    output= [i for i in word_tokens if i not in stopwords]\n",
    "    return \" \".join(output)\n",
    "\n",
    "#applying the function\n",
    "data['no_stopwords']= data['comments_lower'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pol_cat</th>\n",
       "      <th>comments_lower</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>It is simple . She got rejected on bumble and ...</td>\n",
       "      <td>It is simple  She got rejected on bumble and n...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>it is simple  she got rejected on bumble and n...</td>\n",
       "      <td>simple got rejected bumble lashing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8966</th>\n",
       "      <td>Funny thing, Bumble was made by Feminist for f...</td>\n",
       "      <td>Funny thing Bumble was made by Feminist for fe...</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-1</td>\n",
       "      <td>funny thing bumble was made by feminist for fe...</td>\n",
       "      <td>funny thing bumble made feminist feminist stil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9176</th>\n",
       "      <td>bro what? Bumble is the most feminist thing ou...</td>\n",
       "      <td>bro what Bumble is the most feminist thing out...</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>1</td>\n",
       "      <td>bro what bumble is the most feminist thing out...</td>\n",
       "      <td>bro bumble feminist thing true definition femi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8566</th>\n",
       "      <td>This woman is a great example of why men lose ...</td>\n",
       "      <td>This woman is a great example of why men lose ...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>this woman is a great example of why men lose ...</td>\n",
       "      <td>woman great example men lose faith marriage re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>That hasn't been my experience on apps. Yes I ...</td>\n",
       "      <td>That hasnt been my experience on apps Yes I ge...</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>1</td>\n",
       "      <td>that hasnt been my experience on apps yes i ge...</td>\n",
       "      <td>hasnt experience apps yes get bunch messages g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>She is trolling men. A large fraction of her a...</td>\n",
       "      <td>She is trolling men A large fraction of her au...</td>\n",
       "      <td>-0.402679</td>\n",
       "      <td>-1</td>\n",
       "      <td>she is trolling men a large fraction of her au...</td>\n",
       "      <td>trolling men large fraction audience probably ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>Birth control is a choice. In this context, ge...</td>\n",
       "      <td>Birth control is a choice In this context gett...</td>\n",
       "      <td>0.149524</td>\n",
       "      <td>1</td>\n",
       "      <td>birth control is a choice in this context gett...</td>\n",
       "      <td>birth control choice context getting pregnant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>Why does she have loo roll on her Christmas tr...</td>\n",
       "      <td>Why does she have loo roll on her Christmas tree</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>why does she have loo roll on her christmas tree</td>\n",
       "      <td>loo roll christmas tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>Please never get rid of the creaky floor. If y...</td>\n",
       "      <td>Please never get rid of the creaky floor If yo...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>please never get rid of the creaky floor if yo...</td>\n",
       "      <td>please never get rid creaky floor record whate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7268</th>\n",
       "      <td>LOL GIRLS SHOULD BE COMPETEING FOR GOOD MEN!!!...</td>\n",
       "      <td>LOL GIRLS SHOULD BE COMPETEING FOR GOOD MEN Bu...</td>\n",
       "      <td>0.301531</td>\n",
       "      <td>1</td>\n",
       "      <td>lol girls should be competeing for good men bu...</td>\n",
       "      <td>lol girls competeing good men bumble got right...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  \\\n",
       "4504  It is simple . She got rejected on bumble and ...   \n",
       "8966  Funny thing, Bumble was made by Feminist for f...   \n",
       "9176  bro what? Bumble is the most feminist thing ou...   \n",
       "8566  This woman is a great example of why men lose ...   \n",
       "2329  That hasn't been my experience on apps. Yes I ...   \n",
       "4332  She is trolling men. A large fraction of her a...   \n",
       "9306  Birth control is a choice. In this context, ge...   \n",
       "2539  Why does she have loo roll on her Christmas tr...   \n",
       "5844  Please never get rid of the creaky floor. If y...   \n",
       "7268  LOL GIRLS SHOULD BE COMPETEING FOR GOOD MEN!!!...   \n",
       "\n",
       "                                          clean_comment  polarity  pol_cat  \\\n",
       "4504  It is simple  She got rejected on bumble and n...  0.000000       -1   \n",
       "8966  Funny thing Bumble was made by Feminist for fe... -0.166667       -1   \n",
       "9176  bro what Bumble is the most feminist thing out...  0.241667        1   \n",
       "8566  This woman is a great example of why men lose ...  0.800000        1   \n",
       "2329  That hasnt been my experience on apps Yes I ge...  0.293333        1   \n",
       "4332  She is trolling men A large fraction of her au... -0.402679       -1   \n",
       "9306  Birth control is a choice In this context gett...  0.149524        1   \n",
       "2539   Why does she have loo roll on her Christmas tree  0.000000       -1   \n",
       "5844  Please never get rid of the creaky floor If yo...  0.800000        1   \n",
       "7268  LOL GIRLS SHOULD BE COMPETEING FOR GOOD MEN Bu...  0.301531        1   \n",
       "\n",
       "                                         comments_lower  \\\n",
       "4504  it is simple  she got rejected on bumble and n...   \n",
       "8966  funny thing bumble was made by feminist for fe...   \n",
       "9176  bro what bumble is the most feminist thing out...   \n",
       "8566  this woman is a great example of why men lose ...   \n",
       "2329  that hasnt been my experience on apps yes i ge...   \n",
       "4332  she is trolling men a large fraction of her au...   \n",
       "9306  birth control is a choice in this context gett...   \n",
       "2539   why does she have loo roll on her christmas tree   \n",
       "5844  please never get rid of the creaky floor if yo...   \n",
       "7268  lol girls should be competeing for good men bu...   \n",
       "\n",
       "                                           no_stopwords  \n",
       "4504                 simple got rejected bumble lashing  \n",
       "8966  funny thing bumble made feminist feminist stil...  \n",
       "9176  bro bumble feminist thing true definition femi...  \n",
       "8566  woman great example men lose faith marriage re...  \n",
       "2329  hasnt experience apps yes get bunch messages g...  \n",
       "4332  trolling men large fraction audience probably ...  \n",
       "9306  birth control choice context getting pregnant ...  \n",
       "2539                            loo roll christmas tree  \n",
       "5844  please never get rid creaky floor record whate...  \n",
       "7268  lol girls competeing good men bumble got right...  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pol_cat'] = data['pol_cat'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    2275\n",
       "-1    2055\n",
       "Name: pol_cat, dtype: int64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pol_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splittiing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['no_stopwords'], data['pol_cat'],\n",
    "                                        test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "tf_train = vect.fit_transform(X_train)\n",
    "tf_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3464x8099 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 54019 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864318706697459"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8094688221709007"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(tf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = y_test\n",
    "predicted = lr.predict(tf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(random_state=0)\n",
    "clf.fit(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(clf, X_test, y_test)  \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn import metrics\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "#cf = metrics.confusion_matrix(expected, predicted, labels = [1, -1])\n",
    "#print(cf)\n",
    "#fig, ax = plot_confusion_matrix(cf, class_names = [1, -1])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.82      0.80       394\n",
      "           1       0.84      0.80      0.82       472\n",
      "\n",
      "    accuracy                           0.81       866\n",
      "   macro avg       0.81      0.81      0.81       866\n",
      "weighted avg       0.81      0.81      0.81       866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8086398011535983"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(expected, predicted, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1, -1,  1,  1,  1,  1,  1, -1,  1, -1,  1,  1, -1,  1,  1,\n",
       "       -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,\n",
       "       -1, -1, -1,  1,  1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,  1,\n",
       "        1,  1, -1, -1, -1,  1,  1,  1, -1,  1,  1,  1,  1, -1, -1, -1,  1,\n",
       "       -1,  1, -1, -1, -1,  1, -1, -1,  1,  1, -1, -1,  1,  1, -1,  1,  1,\n",
       "       -1,  1,  1,  1, -1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1,  1,  1,\n",
       "        1,  1, -1,  1, -1,  1,  1, -1,  1, -1, -1, -1,  1,  1, -1,  1,  1,\n",
       "       -1,  1,  1,  1, -1, -1, -1, -1, -1,  1, -1,  1, -1,  1, -1, -1, -1,\n",
       "       -1, -1,  1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1, -1, -1,  1,\n",
       "       -1,  1,  1, -1, -1,  1,  1,  1, -1, -1,  1,  1,  1, -1,  1,  1,  1,\n",
       "       -1, -1,  1, -1, -1, -1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1,\n",
       "        1,  1,  1, -1, -1, -1, -1,  1, -1, -1,  1,  1, -1,  1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1,  1,  1,\n",
       "       -1, -1, -1, -1,  1,  1, -1, -1,  1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
       "       -1, -1,  1, -1, -1, -1,  1,  1, -1, -1,  1,  1, -1,  1,  1,  1,  1,\n",
       "        1, -1, -1,  1,  1, -1,  1,  1, -1, -1,  1,  1, -1, -1,  1,  1, -1,\n",
       "       -1,  1, -1, -1, -1, -1, -1, -1,  1,  1, -1,  1,  1, -1, -1,  1,  1,\n",
       "       -1,  1, -1, -1,  1, -1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1,  1,\n",
       "       -1, -1,  1,  1,  1, -1,  1, -1, -1,  1,  1, -1,  1,  1, -1,  1,  1,\n",
       "       -1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1, -1,\n",
       "       -1,  1, -1,  1, -1,  1,  1,  1,  1, -1,  1,  1, -1, -1,  1,  1,  1,\n",
       "        1,  1, -1, -1,  1,  1, -1, -1,  1,  1, -1,  1, -1,  1, -1,  1,  1,\n",
       "       -1, -1, -1, -1,  1, -1,  1, -1,  1, -1, -1, -1, -1,  1,  1, -1, -1,\n",
       "       -1, -1, -1,  1,  1,  1,  1, -1, -1,  1, -1,  1, -1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1, -1, -1, -1, -1, -1,  1,\n",
       "        1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,\n",
       "       -1, -1, -1, -1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1, -1,  1,\n",
       "        1, -1,  1, -1,  1,  1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1,  1,\n",
       "       -1, -1,  1, -1, -1, -1,  1,  1,  1, -1,  1,  1,  1, -1,  1,  1,  1,\n",
       "       -1, -1, -1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1,\n",
       "        1,  1,  1,  1,  1, -1, -1,  1, -1,  1, -1, -1,  1,  1,  1,  1, -1,\n",
       "       -1, -1,  1, -1,  1,  1, -1, -1,  1, -1, -1,  1,  1,  1, -1,  1,  1,\n",
       "        1,  1,  1, -1, -1,  1,  1, -1, -1,  1, -1, -1, -1,  1,  1, -1,  1,\n",
       "        1,  1, -1, -1, -1, -1,  1,  1, -1, -1, -1,  1, -1,  1, -1, -1,  1,\n",
       "       -1, -1, -1, -1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1, -1,  1,  1,\n",
       "       -1,  1,  1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1, -1,  1, -1, -1, -1,\n",
       "       -1, -1,  1, -1, -1, -1,  1,  1,  1,  1,  1,  1, -1,  1, -1, -1, -1,\n",
       "       -1,  1, -1, -1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "        1,  1,  1,  1, -1, -1, -1,  1,  1,  1, -1, -1,  1,  1, -1, -1,  1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1,  1, -1, -1,  1, -1,  1, -1, -1,\n",
       "        1,  1, -1,  1, -1, -1,  1,  1, -1, -1, -1,  1,  1, -1, -1, -1, -1,\n",
       "        1, -1, -1,  1,  1,  1, -1,  1, -1, -1,  1,  1,  1, -1, -1, -1,  1,\n",
       "       -1,  1, -1, -1, -1,  1,  1,  1, -1, -1, -1,  1, -1, -1,  1, -1, -1,\n",
       "        1, -1,  1,  1, -1, -1, -1,  1, -1, -1,  1, -1, -1,  1,  1, -1,  1,\n",
       "       -1, -1, -1,  1,  1, -1,  1, -1, -1, -1,  1,  1,  1, -1,  1, -1,  1,\n",
       "        1,  1,  1, -1,  1,  1,  1, -1,  1, -1, -1, -1, -1,  1,  1, -1, -1,\n",
       "        1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1, -1,  1,  1, -1,\n",
       "       -1, -1,  1, -1, -1,  1, -1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1, -1,  1, -1, -1, -1,  1,  1,  1, -1,  1, -1, -1,  1, -1,  1,\n",
       "        1,  1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1,  1])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(tf_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46847bc71db8794afef264e1700fb1cc88562afa39adb6e94e8f30369d4835a1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('ex_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
